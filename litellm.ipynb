{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Litellm](https://github.com/BerriAI/litellm)\n",
    "Proxy for accessing other models through the same OpenAI methods and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import litellm\n",
    "from litellm import completion\n",
    "litellm.set_verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACE_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is the weather in Gainesville?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92mlitellm.completion(model='huggingface/mistralai/Mixtral-8x7B-Instruct-v0.1', messages=[{'content': 'What is the weather in Gainesville?', 'role': 'user'}])\u001b[0m\n",
      "\n",
      "\n",
      "self.optional_params: {}\n",
      "kwargs[caching]: False; litellm.cache: None\n",
      "self.optional_params: {}\n",
      "mistralai/Mixtral-8x7B-Instruct-v0.1, text-generation-inference\n",
      "response: [{'generated_text': \" I don't have real-time data or location tracking capabilities, so I can't provide you with the current weather in Gainesville. However, I can tell you that Gainesville is located in the state of Florida, USA, and its climate is characterized as humid subtropical, with hot, humid summers and mild, dry winters. The city's weather can be quite variable, with occasional cold fronts bringing cooler temperatures in the winter and\", 'details': {'finish_reason': 'length', 'generated_tokens': 100, 'seed': None, 'prefill': [], 'tokens': [{'id': 315, 'text': ' I', 'logprob': -0.006515503, 'special': False}, {'id': 949, 'text': ' don', 'logprob': -1.5974045e-05, 'special': False}, {'id': 28742, 'text': \"'\", 'logprob': 0.0, 'special': False}, {'id': 28707, 'text': 't', 'logprob': 0.0, 'special': False}, {'id': 506, 'text': ' have', 'logprob': 0.0, 'special': False}, {'id': 1353, 'text': ' real', 'logprob': -4.6491623e-06, 'special': False}, {'id': 28733, 'text': '-', 'logprob': 0.0, 'special': False}, {'id': 1536, 'text': 'time', 'logprob': 0.0, 'special': False}, {'id': 1178, 'text': ' data', 'logprob': -0.6699219, 'special': False}, {'id': 442, 'text': ' or', 'logprob': -9.417534e-06, 'special': False}, {'id': 4723, 'text': ' location', 'logprob': -0.40039062, 'special': False}, {'id': 15271, 'text': ' tracking', 'logprob': -0.00027394295, 'special': False}, {'id': 16585, 'text': ' capabilities', 'logprob': -0.49023438, 'special': False}, {'id': 28725, 'text': ',', 'logprob': -3.540516e-05, 'special': False}, {'id': 579, 'text': ' so', 'logprob': -8.225441e-05, 'special': False}, {'id': 315, 'text': ' I', 'logprob': 0.0, 'special': False}, {'id': 541, 'text': ' can', 'logprob': -0.0009851456, 'special': False}, {'id': 28742, 'text': \"'\", 'logprob': 0.0, 'special': False}, {'id': 28707, 'text': 't', 'logprob': 0.0, 'special': False}, {'id': 3084, 'text': ' provide', 'logprob': -0.032318115, 'special': False}, {'id': 368, 'text': ' you', 'logprob': -0.14331055, 'special': False}, {'id': 395, 'text': ' with', 'logprob': -0.005836487, 'special': False}, {'id': 272, 'text': ' the', 'logprob': -2.6226044e-05, 'special': False}, {'id': 1868, 'text': ' current', 'logprob': -3.5762787e-07, 'special': False}, {'id': 8086, 'text': ' weather', 'logprob': 0.0, 'special': False}, {'id': 297, 'text': ' in', 'logprob': -4.7683716e-07, 'special': False}, {'id': 420, 'text': ' G', 'logprob': 0.0, 'special': False}, {'id': 17251, 'text': 'aines', 'logprob': -5.9604645e-07, 'special': False}, {'id': 5485, 'text': 'ville', 'logprob': 0.0, 'special': False}, {'id': 28723, 'text': '.', 'logprob': -4.887581e-06, 'special': False}, {'id': 2993, 'text': ' However', 'logprob': -5.4001808e-05, 'special': False}, {'id': 28725, 'text': ',', 'logprob': 0.0, 'special': False}, {'id': 315, 'text': ' I', 'logprob': -0.044647217, 'special': False}, {'id': 541, 'text': ' can', 'logprob': -2.6345253e-05, 'special': False}, {'id': 1912, 'text': ' tell', 'logprob': -0.034423828, 'special': False}, {'id': 368, 'text': ' you', 'logprob': 0.0, 'special': False}, {'id': 369, 'text': ' that', 'logprob': -6.890297e-05, 'special': False}, {'id': 420, 'text': ' G', 'logprob': -1.9073486e-06, 'special': False}, {'id': 17251, 'text': 'aines', 'logprob': -1.5497208e-06, 'special': False}, {'id': 5485, 'text': 'ville', 'logprob': 0.0, 'special': False}, {'id': 349, 'text': ' is', 'logprob': -0.00434494, 'special': False}, {'id': 5651, 'text': ' located', 'logprob': -0.0009822845, 'special': False}, {'id': 297, 'text': ' in', 'logprob': 0.0, 'special': False}, {'id': 272, 'text': ' the', 'logprob': -0.14758301, 'special': False}, {'id': 1665, 'text': ' state', 'logprob': -0.0001103878, 'special': False}, {'id': 302, 'text': ' of', 'logprob': 0.0, 'special': False}, {'id': 9500, 'text': ' Florida', 'logprob': 0.0, 'special': False}, {'id': 28725, 'text': ',', 'logprob': -0.00058841705, 'special': False}, {'id': 7035, 'text': ' USA', 'logprob': -0.00033259392, 'special': False}, {'id': 28725, 'text': ',', 'logprob': -0.001411438, 'special': False}, {'id': 304, 'text': ' and', 'logprob': -0.00010430813, 'special': False}, {'id': 871, 'text': ' its', 'logprob': -0.5161133, 'special': False}, {'id': 11259, 'text': ' climate', 'logprob': -0.10321045, 'special': False}, {'id': 349, 'text': ' is', 'logprob': -1.0728836e-06, 'special': False}, {'id': 23100, 'text': ' characterized', 'logprob': -0.11706543, 'special': False}, {'id': 390, 'text': ' as', 'logprob': -0.0010490417, 'special': False}, {'id': 1997, 'text': ' hum', 'logprob': -0.10192871, 'special': False}, {'id': 313, 'text': 'id', 'logprob': 0.0, 'special': False}, {'id': 1083, 'text': ' sub', 'logprob': -2.2649765e-06, 'special': False}, {'id': 28707, 'text': 't', 'logprob': 0.0, 'special': False}, {'id': 1506, 'text': 'rop', 'logprob': 0.0, 'special': False}, {'id': 745, 'text': 'ical', 'logprob': 0.0, 'special': False}, {'id': 28725, 'text': ',', 'logprob': -0.56933594, 'special': False}, {'id': 395, 'text': ' with', 'logprob': -0.01373291, 'special': False}, {'id': 3296, 'text': ' hot', 'logprob': -1.66893e-06, 'special': False}, {'id': 28725, 'text': ',', 'logprob': -0.009780884, 'special': False}, {'id': 1997, 'text': ' hum', 'logprob': -0.0059394836, 'special': False}, {'id': 313, 'text': 'id', 'logprob': 0.0, 'special': False}, {'id': 2648, 'text': ' sum', 'logprob': -2.1457672e-06, 'special': False}, {'id': 14448, 'text': 'mers', 'logprob': 0.0, 'special': False}, {'id': 304, 'text': ' and', 'logprob': -4.7683716e-07, 'special': False}, {'id': 16583, 'text': ' mild', 'logprob': -0.0019302368, 'special': False}, {'id': 28725, 'text': ',', 'logprob': -0.071899414, 'special': False}, {'id': 6964, 'text': ' dry', 'logprob': -0.014038086, 'special': False}, {'id': 3108, 'text': ' win', 'logprob': -1.1086464e-05, 'special': False}, {'id': 1532, 'text': 'ters', 'logprob': 0.0, 'special': False}, {'id': 28723, 'text': '.', 'logprob': 0.0, 'special': False}, {'id': 415, 'text': ' The', 'logprob': -0.33325195, 'special': False}, {'id': 2990, 'text': ' city', 'logprob': -0.88964844, 'special': False}, {'id': 28742, 'text': \"'\", 'logprob': -0.32885742, 'special': False}, {'id': 28713, 'text': 's', 'logprob': -2.1457672e-06, 'special': False}, {'id': 8086, 'text': ' weather', 'logprob': -0.086364746, 'special': False}, {'id': 541, 'text': ' can', 'logprob': -0.0049934387, 'special': False}, {'id': 347, 'text': ' be', 'logprob': -0.67822266, 'special': False}, {'id': 3448, 'text': ' quite', 'logprob': -0.41137695, 'special': False}, {'id': 7860, 'text': ' variable', 'logprob': -0.0023651123, 'special': False}, {'id': 28725, 'text': ',', 'logprob': -0.03805542, 'special': False}, {'id': 395, 'text': ' with', 'logprob': -0.48095703, 'special': False}, {'id': 20636, 'text': ' occasional', 'logprob': -0.45239258, 'special': False}, {'id': 5256, 'text': ' cold', 'logprob': -0.041656494, 'special': False}, {'id': 2778, 'text': ' front', 'logprob': -8.702278e-06, 'special': False}, {'id': 28713, 'text': 's', 'logprob': 0.0, 'special': False}, {'id': 10279, 'text': ' bringing', 'logprob': -0.5439453, 'special': False}, {'id': 5106, 'text': ' cool', 'logprob': -0.045440674, 'special': False}, {'id': 263, 'text': 'er', 'logprob': 0.0, 'special': False}, {'id': 17991, 'text': ' temperatures', 'logprob': -0.06201172, 'special': False}, {'id': 297, 'text': ' in', 'logprob': -0.028839111, 'special': False}, {'id': 272, 'text': ' the', 'logprob': -0.0029392242, 'special': False}, {'id': 8539, 'text': ' winter', 'logprob': -7.1525574e-07, 'special': False}, {'id': 304, 'text': ' and', 'logprob': -0.008766174, 'special': False}]}}]\n",
      "Looking up model=mistralai/Mixtral-8x7B-Instruct-v0.1 in model_cost_map\n",
      "\n",
      "\n",
      "  I don't have real-time data or location tracking capabilities, so I can't provide you with the current weather in Gainesville. However, I can tell you that Gainesville is located in the state of Florida, USA, and its climate is characterized as humid subtropical, with hot, humid summers and mild, dry winters. The city's weather can be quite variable, with occasional cold fronts bringing cooler temperatures in the winter and\n"
     ]
    }
   ],
   "source": [
    "response = completion(\n",
    "  model=\"huggingface/mistralai/Mixtral-8x7B-Instruct-v0.1\", \n",
    "  messages=[{ \"content\": prompt,\"role\": \"user\"}], \n",
    ")\n",
    "\n",
    "print(\"\\n\\n\", response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92mlitellm.embedding(model='huggingface/microsoft/codebert-base', input=['What is the weather in Gainesville?'])\u001b[0m\n",
      "\n",
      "\n",
      "self.optional_params: {}\n",
      "kwargs[caching]: False; litellm.cache: None\n",
      "self.optional_params: {}\n",
      "Looking up model=microsoft/codebert-base in model_cost_map\n",
      " [-0.08081008493900299, 0.38493189215660095, 0.0964692234992981, -0.007553956937044859, 0.1546626091003418, -0.15101437270641327, -0.11523221433162689, 0.026286721229553223, 0.09007897228002548, -0.16575567424297333]\n",
      "\n",
      "shape (768,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from litellm import embedding\n",
    "import os\n",
    "response = embedding(\n",
    "    model='huggingface/microsoft/codebert-base',\n",
    "    input=[prompt]\n",
    ")\n",
    "# show the first 10 values of the embedding\n",
    "print(\"\\n\", response.data[0][\"embedding\"][:10])\n",
    "print(\"\\nshape\", np.array(response.data[0][\"embedding\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have real-time data or the ability to provide current weather updates. I recommend checking a reliable weather forecasting website or app for the most accurate and up-to-date information on the weather in Gainesville. Gainesville is located in the state of Florida, USA, and is known for its subtropical climate with hot, humid summers and mild, dry winters. However, the weather can vary throughout the year, so it's alwaysGoes into checking if chunk has hiddden created at param\n",
      "Chunks have a created at hidden param\n",
      "Chunks sorted\n",
      "token_counter messages received: [{'content': 'What is the weather in Gainesville?', 'role': 'user'}]\n",
      "Token Counter - using generic token counter, for model=mistralai/Mixtral-8x7B-Instruct-v0.1\n",
      "LiteLLM: Utils - Counting tokens for OpenAI model=gpt-3.5-turbo\n",
      "Token Counter - using generic token counter, for model=mistralai/Mixtral-8x7B-Instruct-v0.1\n",
      "LiteLLM: Utils - Counting tokens for OpenAI model=gpt-3.5-turbo\n",
      "Looking up model=mistralai/Mixtral-8x7B-Instruct-v0.1 in model_cost_map\n",
      "Goes into checking if chunk has hiddden created at param\n",
      "Chunks have a created at hidden param\n",
      "Chunks sorted\n",
      "token_counter messages received: [{'content': 'What is the weather in Gainesville?', 'role': 'user'}]\n",
      "Token Counter - using generic token counter, for model=mistralai/Mixtral-8x7B-Instruct-v0.1\n",
      "LiteLLM: Utils - Counting tokens for OpenAI model=gpt-3.5-turbo\n",
      "Token Counter - using generic token counter, for model=mistralai/Mixtral-8x7B-Instruct-v0.1\n",
      "LiteLLM: Utils - Counting tokens for OpenAI model=gpt-3.5-turbo\n",
      "Looking up model=mistralai/Mixtral-8x7B-Instruct-v0.1 in model_cost_map\n"
     ]
    }
   ],
   "source": [
    "litellm.set_verbose = False\n",
    "\n",
    "response = completion(\n",
    "  model=\"huggingface/mistralai/Mixtral-8x7B-Instruct-v0.1\", \n",
    "  messages=[{ \"content\": prompt, \"role\": \"user\"}], \n",
    "  api_base=\"https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "  stream=True,\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "  print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n",
    "litellm.set_verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How was it instant?\n",
    "### What is contained in the chunks of the stream (full generatio or tokens)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By superimposing to the prompt the model is able to exhibit functionalities of other LLMs\n",
    "https://github.com/BerriAI/litellm/blob/d69edac11ba4acdb03116cde253cc0d7caadcf68/litellm/llms/prompt_templates/factory.py#L531-L545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92mlitellm.completion(model='huggingface/mistralai/Mixtral-8x7B-Instruct-v0.1', messages=[{'content': 'Answer in spanish', 'role': 'system'}, {'content': 'Get the weather in SF?', 'role': 'user'}], functions=[{'name': 'get_current_weather', 'description': 'Get the current weather in a given location', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The city and state, e.g. San Francisco, CA'}, 'unit': {'type': 'string', 'enum': ['celsius', 'fahrenheit']}}, 'required': ['location']}}])\u001b[0m\n",
      "\n",
      "\n",
      "self.optional_params: {}\n",
      "kwargs[caching]: False; litellm.cache: None\n",
      "self.optional_params: {}\n",
      "mistralai/Mixtral-8x7B-Instruct-v0.1, text-generation-inference\n",
      "response: [{'generated_text': ' {\\n\"function\\\\_name\": \"get\\\\_current\\\\_weather\",\\n\"parameters\": {\\n\"location\": \"San Francisco, CA\",\\n\"unit\": \"fahrenheit\"\\n}\\n}', 'details': {'finish_reason': 'eos_token', 'generated_tokens': 44, 'seed': None, 'prefill': [], 'tokens': [{'id': 371, 'text': ' {', 'logprob': -0.06121826, 'special': False}, {'id': 13, 'text': '\\n', 'logprob': 0.0, 'special': False}, {'id': 28739, 'text': '\"', 'logprob': -0.000500679, 'special': False}, {'id': 2628, 'text': 'function', 'logprob': -0.24145508, 'special': False}, {'id': 14048, 'text': '\\\\_', 'logprob': -0.60839844, 'special': False}, {'id': 861, 'text': 'name', 'logprob': -4.2915344e-06, 'special': False}, {'id': 1264, 'text': '\":', 'logprob': -1.5258789e-05, 'special': False}, {'id': 345, 'text': ' \"', 'logprob': -9.536743e-07, 'special': False}, {'id': 527, 'text': 'get', 'logprob': 0.0, 'special': False}, {'id': 14048, 'text': '\\\\_', 'logprob': 0.0, 'special': False}, {'id': 3022, 'text': 'current', 'logprob': 0.0, 'special': False}, {'id': 14048, 'text': '\\\\_', 'logprob': -1.4305115e-06, 'special': False}, {'id': 769, 'text': 'we', 'logprob': 0.0, 'special': False}, {'id': 1223, 'text': 'ather', 'logprob': 0.0, 'special': False}, {'id': 548, 'text': '\",', 'logprob': 0.0, 'special': False}, {'id': 13, 'text': '\\n', 'logprob': 0.0, 'special': False}, {'id': 28739, 'text': '\"', 'logprob': 0.0, 'special': False}, {'id': 11438, 'text': 'parameters', 'logprob': -2.4914742e-05, 'special': False}, {'id': 1264, 'text': '\":', 'logprob': 0.0, 'special': False}, {'id': 371, 'text': ' {', 'logprob': -1.1920929e-07, 'special': False}, {'id': 13, 'text': '\\n', 'logprob': 0.0, 'special': False}, {'id': 28739, 'text': '\"', 'logprob': -2.7418137e-06, 'special': False}, {'id': 2733, 'text': 'location', 'logprob': -4.7683716e-07, 'special': False}, {'id': 1264, 'text': '\":', 'logprob': 0.0, 'special': False}, {'id': 345, 'text': ' \"', 'logprob': 0.0, 'special': False}, {'id': 17904, 'text': 'San', 'logprob': -2.3841858e-07, 'special': False}, {'id': 9686, 'text': ' Francisco', 'logprob': -3.8146973e-06, 'special': False}, {'id': 28725, 'text': ',', 'logprob': 0.0, 'special': False}, {'id': 9461, 'text': ' CA', 'logprob': 0.0, 'special': False}, {'id': 548, 'text': '\",', 'logprob': -1.1920929e-07, 'special': False}, {'id': 13, 'text': '\\n', 'logprob': 0.0, 'special': False}, {'id': 28739, 'text': '\"', 'logprob': 0.0, 'special': False}, {'id': 5306, 'text': 'unit', 'logprob': -2.3841858e-07, 'special': False}, {'id': 1264, 'text': '\":', 'logprob': 0.0, 'special': False}, {'id': 345, 'text': ' \"', 'logprob': 0.0, 'special': False}, {'id': 28722, 'text': 'f', 'logprob': -1.1920929e-07, 'special': False}, {'id': 18657, 'text': 'ahren', 'logprob': 0.0, 'special': False}, {'id': 12307, 'text': 'heit', 'logprob': 0.0, 'special': False}, {'id': 28739, 'text': '\"', 'logprob': 0.0, 'special': False}, {'id': 13, 'text': '\\n', 'logprob': 0.0, 'special': False}, {'id': 28752, 'text': '}', 'logprob': 0.0, 'special': False}, {'id': 13, 'text': '\\n', 'logprob': 0.0, 'special': False}, {'id': 28752, 'text': '}', 'logprob': 0.0, 'special': False}, {'id': 2, 'text': '</s>', 'logprob': -0.0017852783, 'special': True}]}}]\n",
      "Looking up model=mistralai/Mixtral-8x7B-Instruct-v0.1 in model_cost_map\n",
      "\n",
      "\n",
      "content:  {\n",
      "\"function\\_name\": \"get\\_current\\_weather\",\n",
      "\"parameters\": {\n",
      "\"location\": \"San Francisco, CA\",\n",
      "\"unit\": \"fahrenheit\"\n",
      "}\n",
      "}\n",
      "json_content: {\n",
      "  \"function_name\": \"get_current_weather\",\n",
      "  \"parameters\": {\n",
      "    \"location\": \"San Francisco, CA\",\n",
      "    \"unit\": \"fahrenheit\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "litellm.add_function_to_prompt = True \n",
    "response = completion(\n",
    "  model=\"huggingface/mistralai/Mixtral-8x7B-Instruct-v0.1\", \n",
    "  messages=[\n",
    "    { \"content\": \"Answer in spanish\", \"role\": \"system\"},\n",
    "    { \"content\": \"Get the weather in SF?\",\"role\": \"user\"}\n",
    "  ],\n",
    "  functions = [\n",
    "    {\n",
    "      \"name\": \"get_current_weather\",\n",
    "      \"description\": \"Get the current weather in a given location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "          },\n",
    "          \"unit\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    ")\n",
    "content = response.choices[0].message.content\n",
    "print(\"\\n\\ncontent:\", content)\n",
    "import json\n",
    "content = response.choices[0].message.content\n",
    "\n",
    "\n",
    "modified_content = content.replace('\\_', '_')\n",
    "json_content = json.loads(modified_content)\n",
    "print(\"json_content:\", json.dumps(json_content, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92mlitellm.completion(model='huggingface/tiiuae/falcon-7b-instruct', messages=[{'content': 'Answer in spanish', 'role': 'system'}, {'content': 'Get the weather in SF?', 'role': 'user'}], functions=[{'name': 'get_current_weather', 'description': 'Get the current weather in a given location', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The city and state, e.g. San Francisco, CA'}, 'unit': {'type': 'string', 'enum': ['celsius', 'fahrenheit']}}, 'required': ['location']}}])\u001b[0m\n",
      "\n",
      "\n",
      "self.optional_params: {}\n",
      "kwargs[caching]: False; litellm.cache: None\n",
      "self.optional_params: {}\n",
      "tiiuae/falcon-7b-instruct, text-generation-inference\n",
      "response: [{'generated_text': \"<p>The following is an example of how to get the current weather in a given location using the <code>get_current_weather</code> function:</p>\\n\\n<pre><code>import requests\\n\\nlocation = 'San Francisco, CA'\\nweather = requests.get('https://openweathermap.org/data/2.5/weather?q={}&appid=YOUR_API_KEY'.format(location))\\n\", 'details': {'finish_reason': 'length', 'generated_tokens': 100, 'seed': None, 'prefill': [], 'tokens': [{'id': 39, 'text': '<', 'logprob': -1.0703125, 'special': False}, {'id': 91, 'text': 'p', 'logprob': -1.0820312, 'special': False}, {'id': 41, 'text': '>', 'logprob': -0.09979248, 'special': False}, {'id': 487, 'text': 'The', 'logprob': -1.3759766, 'special': False}, {'id': 1863, 'text': ' following', 'logprob': -1.4990234, 'special': False}, {'id': 304, 'text': ' is', 'logprob': -1.6542969, 'special': False}, {'id': 267, 'text': ' an', 'logprob': -0.72509766, 'special': False}, {'id': 1945, 'text': ' example', 'logprob': -0.09094238, 'special': False}, {'id': 275, 'text': ' of', 'logprob': -0.39208984, 'special': False}, {'id': 672, 'text': ' how', 'logprob': -0.6791992, 'special': False}, {'id': 271, 'text': ' to', 'logprob': -0.45361328, 'special': False}, {'id': 577, 'text': ' get', 'logprob': -1.3251953, 'special': False}, {'id': 248, 'text': ' the', 'logprob': -0.21191406, 'special': False}, {'id': 1539, 'text': ' current', 'logprob': -0.48486328, 'special': False}, {'id': 5015, 'text': ' weather', 'logprob': -0.042022705, 'special': False}, {'id': 272, 'text': ' in', 'logprob': -0.15014648, 'special': False}, {'id': 241, 'text': ' a', 'logprob': -0.5996094, 'special': False}, {'id': 2132, 'text': ' given', 'logprob': -0.65478516, 'special': False}, {'id': 3584, 'text': ' location', 'logprob': -0.05355835, 'special': False}, {'id': 1241, 'text': ' using', 'logprob': -0.3173828, 'special': False}, {'id': 248, 'text': ' the', 'logprob': -0.46240234, 'special': False}, {'id': 204, 'text': ' ', 'logprob': -1.5507812, 'special': False}, {'id': 39, 'text': '<', 'logprob': -0.52490234, 'special': False}, {'id': 5779, 'text': 'code', 'logprob': -0.10003662, 'special': False}, {'id': 41, 'text': '>', 'logprob': -0.011077881, 'special': False}, {'id': 710, 'text': 'get', 'logprob': -0.8911133, 'special': False}, {'id': 74, 'text': '_', 'logprob': -0.083496094, 'special': False}, {'id': 9134, 'text': 'current', 'logprob': -0.03955078, 'special': False}, {'id': 74, 'text': '_', 'logprob': -0.0014858246, 'special': False}, {'id': 33922, 'text': 'weather', 'logprob': -0.016815186, 'special': False}, {'id': 1686, 'text': '</', 'logprob': -0.2788086, 'special': False}, {'id': 5779, 'text': 'code', 'logprob': -0.00074481964, 'special': False}, {'id': 41, 'text': '>', 'logprob': -0.0028915405, 'special': False}, {'id': 1935, 'text': ' function', 'logprob': -0.3293457, 'special': False}, {'id': 37375, 'text': ':</', 'logprob': -0.8129883, 'special': False}, {'id': 91, 'text': 'p', 'logprob': -0.0010099411, 'special': False}, {'id': 41, 'text': '>', 'logprob': -0.0032596588, 'special': False}, {'id': 1001, 'text': '\\n\\n', 'logprob': -0.10406494, 'special': False}, {'id': 39, 'text': '<', 'logprob': -0.027328491, 'special': False}, {'id': 2121, 'text': 'pre', 'logprob': -0.27539062, 'special': False}, {'id': 4836, 'text': '><', 'logprob': -0.027023315, 'special': False}, {'id': 5779, 'text': 'code', 'logprob': -0.0014152527, 'special': False}, {'id': 41, 'text': '>', 'logprob': -0.042907715, 'special': False}, {'id': 2363, 'text': 'import', 'logprob': -0.71533203, 'special': False}, {'id': 9082, 'text': ' requests', 'logprob': -0.2442627, 'special': False}, {'id': 193, 'text': '\\n', 'logprob': -0.16491699, 'special': False}, {'id': 193, 'text': '\\n', 'logprob': -0.67041016, 'special': False}, {'id': 17746, 'text': 'location', 'logprob': -1.5419922, 'special': False}, {'id': 204, 'text': ' ', 'logprob': -0.027740479, 'special': False}, {'id': 40, 'text': '=', 'logprob': -0.0014228821, 'special': False}, {'id': 204, 'text': ' ', 'logprob': -0.15185547, 'special': False}, {'id': 18, 'text': \"'\", 'logprob': -0.46264648, 'special': False}, {'id': 15379, 'text': 'San', 'logprob': -0.093322754, 'special': False}, {'id': 8863, 'text': ' Francisco', 'logprob': -0.0042495728, 'special': False}, {'id': 23, 'text': ',', 'logprob': -0.12426758, 'special': False}, {'id': 6419, 'text': ' CA', 'logprob': -0.032104492, 'special': False}, {'id': 18, 'text': \"'\", 'logprob': -0.01927185, 'special': False}, {'id': 193, 'text': '\\n', 'logprob': -0.09814453, 'special': False}, {'id': 33922, 'text': 'weather', 'logprob': -1.3886719, 'special': False}, {'id': 204, 'text': ' ', 'logprob': -0.44433594, 'special': False}, {'id': 40, 'text': '=', 'logprob': -0.0007286072, 'special': False}, {'id': 9082, 'text': ' requests', 'logprob': -0.20007324, 'special': False}, {'id': 25, 'text': '.', 'logprob': -0.015556335, 'special': False}, {'id': 710, 'text': 'get', 'logprob': -0.020111084, 'special': False}, {'id': 2517, 'text': \"('\", 'logprob': -0.3215332, 'special': False}, {'id': 12659, 'text': 'https', 'logprob': -0.47558594, 'special': False}, {'id': 7561, 'text': '://', 'logprob': -0.006088257, 'special': False}, {'id': 7691, 'text': 'open', 'logprob': -1.265625, 'special': False}, {'id': 33922, 'text': 'weather', 'logprob': -0.15246582, 'special': False}, {'id': 6499, 'text': 'map', 'logprob': -0.0035514832, 'special': False}, {'id': 25, 'text': '.', 'logprob': -0.009864807, 'special': False}, {'id': 3128, 'text': 'org', 'logprob': -0.060150146, 'special': False}, {'id': 26, 'text': '/', 'logprob': -0.00868988, 'special': False}, {'id': 3762, 'text': 'data', 'logprob': -0.4946289, 'special': False}, {'id': 26, 'text': '/', 'logprob': -0.0099105835, 'special': False}, {'id': 29, 'text': '2', 'logprob': -0.031921387, 'special': False}, {'id': 25, 'text': '.', 'logprob': -0.0075645447, 'special': False}, {'id': 32, 'text': '5', 'logprob': -0.01285553, 'special': False}, {'id': 26, 'text': '/', 'logprob': -0.019119263, 'special': False}, {'id': 33922, 'text': 'weather', 'logprob': -0.16223145, 'special': False}, {'id': 42, 'text': '?', 'logprob': -0.1973877, 'special': False}, {'id': 92, 'text': 'q', 'logprob': -0.23791504, 'special': False}, {'id': 40, 'text': '=', 'logprob': -0.76660156, 'special': False}, {'id': 8265, 'text': '{}', 'logprob': -0.013389587, 'special': False}, {'id': 17, 'text': '&', 'logprob': -0.42871094, 'special': False}, {'id': 1248, 'text': 'app', 'logprob': -0.15637207, 'special': False}, {'id': 300, 'text': 'id', 'logprob': -0.030975342, 'special': False}, {'id': 40, 'text': '=', 'logprob': -0.062042236, 'special': False}, {'id': 21613, 'text': 'YO', 'logprob': -0.90527344, 'special': False}, {'id': 3106, 'text': 'UR', 'logprob': -0.00466156, 'special': False}, {'id': 74, 'text': '_', 'logprob': -0.0042152405, 'special': False}, {'id': 14748, 'text': 'API', 'logprob': -0.5800781, 'special': False}, {'id': 74, 'text': '_', 'logprob': -0.002614975, 'special': False}, {'id': 18262, 'text': 'KEY', 'logprob': -0.019622803, 'special': False}, {'id': 6304, 'text': \"'.\", 'logprob': -0.45751953, 'special': False}, {'id': 9515, 'text': 'format', 'logprob': -0.0005106926, 'special': False}, {'id': 19, 'text': '(', 'logprob': -0.0056877136, 'special': False}, {'id': 17746, 'text': 'location', 'logprob': -0.024337769, 'special': False}, {'id': 2359, 'text': '))', 'logprob': -0.38964844, 'special': False}, {'id': 193, 'text': '\\n', 'logprob': -0.05230713, 'special': False}]}}]\n",
      "Looking up model=tiiuae/falcon-7b-instruct in model_cost_map\n",
      "\n",
      "\n",
      "content: <p>The following is an example of how to get the current weather in a given location using the <code>get_current_weather</code> function:</p>\n",
      "\n",
      "<pre><code>import requests\n",
      "\n",
      "location = 'San Francisco, CA'\n",
      "weather = requests.get('https://openweathermap.org/data/2.5/weather?q={}&appid=YOUR_API_KEY'.format(location))\n",
      "\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 36\u001b[0m\n\u001b[0;32m     32\u001b[0m content \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m     35\u001b[0m modified_content \u001b[38;5;241m=\u001b[39m content\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m json_content \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodified_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson_content:\u001b[39m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(json_content, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[1;32mC:\\Python310\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mC:\\Python310\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mC:\\Python310\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "litellm.add_function_to_prompt = True \n",
    "response = completion(\n",
    "  model=\"huggingface/tiiuae/falcon-7b-instruct\", \n",
    "  messages=[\n",
    "    { \"content\": \"Answer in spanish\", \"role\": \"system\"},\n",
    "    { \"content\": \"Get the weather in SF?\",\"role\": \"user\"}\n",
    "  ],\n",
    "  functions = [\n",
    "    {\n",
    "      \"name\": \"get_current_weather\",\n",
    "      \"description\": \"Get the current weather in a given location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "          },\n",
    "          \"unit\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    ")\n",
    "content = response.choices[0].message.content\n",
    "print(\"\\n\\ncontent:\", content)\n",
    "import json\n",
    "content = response.choices[0].message.content\n",
    "\n",
    "\n",
    "modified_content = content.replace('\\_', '_')\n",
    "json_content = json.loads(modified_content)\n",
    "print(\"json_content:\", json.dumps(json_content, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " (2, 3, 1)\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[[1],[2],[3]],[[4],[5],[6]]])\n",
    "print(\"\\n\", arr.shape)\n",
    "# reshape it to flatten the innermost dimension so as to make a array of shape (2, 3)\n",
    "arr = arr.reshape(arr.shape[0], -1)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
